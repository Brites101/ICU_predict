{"cells":[{"metadata":{},"cell_type":"markdown","source":"Nela, encontramos diversos tipos de informações que foram separadas em 4 grupos:\n\nInformação demográfica - 3 variáveis\nDoenças pré-existentes - 9 variáveis\nResultados do exame de sangue - 36 variáveis\nSinais vitais - 6 variáveis\nSabemos que há urgência na obtenção e manipulação de dados para melhorar a previsão e assim, conseguir preparar o sistema de saúde, evitando colapsos.\n\nNosso objetivo será prever quais pacientes precisarão ser admitidos na unidade de terapia intensiva e assim, definir qual a necessidade de leitos de UTI do hospital, a partir dos dados clínicos individuais disponíveis.\n\nQuando conseguimos definir a quantidade de leitos necessários em um determinado hospital, conseguimos evitar rupturas, visto que, caso outra pessoa procure ajuda e, eventualmente, precise de cuidados intensivos, o modelo preditivo já conseguirá detectar essa necessidade e, desta forma, a remoção e transferência deste paciente pode ser organizada antecipadamente.\n\nQueremos que você aplique tudo o que aprendeu durante toda sua trajetória no Bootcamp e construa um modelo com as técnicas de Machine Learning que busquem a nossa variável-resposta.\n\nTenha em mente que este projeto será apresentado, de maneira fictícia, para o gerente responsável pela modelagem de dados do time de Data Science do Hospital Sírio Libanês. Você precisará persuadi-lo de que seu modelo tem os pontos necessários para entrar em produção e ajudará a antever e evitar qualquer ruptura.\n\nComo a entrega é obrigatória para certificação, montamos um conjunto de critérios mínimos para avaliação que vocês poderão usar como um guia para montar seu estudo.\n\nTemos dois blocos a serem considerados:\n\nTécnico\nPrático\nNa seção de critérios mínimos deste projeto, você encontra quais são os aspectos que compõem estes blocos e suas respectivas descrições.\n\nPara que o seu projeto seja avaliado pelo Thiago G. Santos e Átila Iamarino, ao vivo, na live de revisão de projetos, submeta seu notebook ou a URL do seu projeto público no GitHub até dia 24/02 às 23h59.}"},{"metadata":{},"cell_type":"markdown","source":"# Descrição do Problema\n\nA pandemia do novo coronavirus sobrecarregou o sistema hospitalar global durante meses. Despreparados para a demanda longa e volumosa, solicitações por leitos nas Unidades de Tratamento Intensivo (UTI), equipamentos e profissionais ultrapassaram os recursos disponiveis para praticamente todos os hospitais do país. O primeiro caso de COVID-19 no Brasil foi identificado em 26 de Fevereiro de 2020 e desde então, otimizar alocação de recursos na UTI tem sido uma prioridade.\n\n## Call To Action\n\nSabemos que existe um espectro amplo de casos de COVID-19. Desde pacientes assintomaticos até pacientes necessitando respiração mecânica. Nesse estudo, vamos tentar entender os principais indicadores que levam um paciente para UTI, assim como desenvolver um modelo que nos permita identificar se um paciente precisará ser direcionado para a UTI ou não facilitar a previsão de demanda de leitos de UTI. "},{"metadata":{},"cell_type":"markdown","source":"# O Modelo\n\nPara auxiliar na tomada de decisão UTI\n\n### Nossa Variável resposta\n\nNa nossa base de dados, a coluna ```ICU``` indica se aquela observação foi feita na UTI (1) ou não (0). Entender a sutileza desse indicador é extramente importante para nossos proximos passos. A coluna ```ICU``` não descreve quando houve solicitação de um leito de UTI. Além disso, sabemos que a transferencia de um paciente da emergencia/triagem para um leito de UTI pode demorar significativamente. **Esses dois fatores tornam enfraquecem o vínculo das variáveis. ```WINDOW``` e ```ICU```.**\n\nBaseado nisso, nosso modelo se propões a identificar, na triagem inicial, se o paciente deve ser alocado na UTI ou não. Não vai importar para gente quantas horas demorou para ele ser alocado na UTI. Nossa variável resposta vai identificar se o paciente foi eventualmente para a UTI ou não. "},{"metadata":{},"cell_type":"markdown","source":"# Dados Faltando\n\n\n\"A falta de respostas também é uma resposta\""},{"metadata":{},"cell_type":"markdown","source":"\n## Como é feito o Monitoramento"},{"metadata":{},"cell_type":"markdown","source":"## Como classificar dados faltantes \n\nExistem algumas opções de tratamento para dados com ```NaN```. Nesse estudo vamos usar ```NaN = 0```.\n\nTentar preencher esse valor vazio com médias ou valores obtidos em outras observações simplesmente ignoraria o fato de que, em produção, nosso algoritmo terá de lidar com a ausencia de certos valores, de acordo com a falta de certos tipos de monitoramento ou exames. Portanto, é conceitualmente inviável utilizarmos dados futuros para realizar nossa previsão, pois nossos usuários finais não terão acesso à eles no dia-a-dia. \n\nTambém existe um problema que existe gerado utilizarmos ```NaN = 0```. Porque o valor zero vai passar a descrever duas situações diferentes. zero vai representar tanto a não mensuração, quanto a mensuração igual à zero, que sáo conceitualmente diferentes. Acredito que isso não vai gerar problemas porque (i)mensurações iguais a zero são pouco representativas e (ii)a falta de mensurações também será capturada nas variáveis de monitoramento feito, que definimos na seção anterior."},{"metadata":{},"cell_type":"markdown","source":"#"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importar dados e bibliotecas"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n!pip install openpyxl\n\nimport openpyxl\nfrom itertools import combinations\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\n\nimport matplotlib.pyplot as plt \nimport plotly.graph_objects as go\n\n\npd.set_option('display.max_columns', 500)","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting openpyxl\n  Downloading openpyxl-3.0.6-py2.py3-none-any.whl (242 kB)\n\u001b[K     |████████████████████████████████| 242 kB 3.0 MB/s eta 0:00:01\n\u001b[?25hCollecting et-xmlfile\n  Downloading et_xmlfile-1.0.1.tar.gz (8.4 kB)\nCollecting jdcal\n  Downloading jdcal-1.4.1-py2.py3-none-any.whl (9.5 kB)\nBuilding wheels for collected packages: et-xmlfile\n  Building wheel for et-xmlfile (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for et-xmlfile: filename=et_xmlfile-1.0.1-py3-none-any.whl size=8913 sha256=8b93f1d11b2a565b21286e6a4c93344f40407cde94f19bceb49286a5bf6538cb\n  Stored in directory: /root/.cache/pip/wheels/e2/bd/55/048b4fd505716c4c298f42ee02dffd9496bb6d212b266c7f31\nSuccessfully built et-xmlfile\nInstalling collected packages: jdcal, et-xmlfile, openpyxl\nSuccessfully installed et-xmlfile-1.0.1 jdcal-1.4.1 openpyxl-3.0.6\n\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_excel('/kaggle/input/covid19/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TRATANDO A BASE DE DADOS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Para facilitar leitura vamos ordernar o dataframe de acordo com o identificador de cada paciente e a janela da visita desse paciente.\ndf.sort_values(['PATIENT_VISIT_IDENTIFIER','WINDOW'],inplace=True)\n\n#ajustar para que todas as colunas binárias sigam  o padrão 0 ou 1.\nadapt_bool = df[df.columns[df.nunique() == 1]]\nadapt_bool = adapt_bool.fillna(0)\nadapt_bool = adapt_bool.abs()\ndf[df.columns[df.nunique() == 1]] = adapt_bool\n\n# Existe um paciente com registros defeituosos. Dado que isso só ocorre com um dos pacientes, vamos eliminar ele do nosso dataset.\ndf.drop(df[df['PATIENT_VISIT_IDENTIFIER']==199].index,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Existem diversas colunas com valores repetidos. Vamos criar uma função para identificar conjuntos de colunas repetidas, então vamos agregar cada conjunto de colunas repetidas em uma única coluna."},{"metadata":{"trusted":true},"cell_type":"code","source":"class RepeatedSet:\n    def __init__(self,d,l):\n        self.d = d\n        self.l = l\n\ndef repeated_columns(dataframe):\n    \n    \"\"\"This function takes a DataFrame Object and return a dictionary with \n    all sets of columns that contains the same values. \n    \n    The keys of the dictionary are the names of the column used to compare values \"\"\"\n    \n    temp = dataframe.copy()\n    repeated_sets={}\n\n    for j in dataframe.columns:\n        if j in temp.columns:\n            repeats =[]\n            for i in dataframe.columns: \n                repeats.append(temp[j].equals(dataframe[i]))\n            if repeats.count(True) > 1:\n                repeated_sets[j] = dataframe.columns[repeats].to_list()[1:]\n            else:\n                pass\n            temp.drop(dataframe.columns[repeats].to_list(),axis = 1,inplace=True)\n        else:\n            pass\n    return RepeatedSet(repeated_sets,[item for sublist in repeated_sets.values() for item in sublist])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop redundant columns\nsets= repeated_columns(df)\ndf.drop(sets.l,axis=1,inplace=True)\n\n#Create map for redudant sets\ncolumn_maps = dict(zip(list(sets.d.keys())[2:],[item[:item.rindex('_')] for item in list(sets.d.keys())[2:]]))\ncolumn_maps['ALBUMIN_MEDIAN'] = 'ALBUMIN'\ncolumn_maps['ALBUMIN_DIFF'] = 'DIFF_SET'\n#Rename columns that represent the redudant sets\ndf.rename(columns=column_maps,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para esssa análise, também estamos escolhendo não analisar genero do paciente."},{"metadata":{"trusted":true},"cell_type":"code","source":"#I dont want to use gender in this analysis\ndf.drop('GENDER',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos agrupar os dados em 4 categorias diferentes:\n\n1. Demográfico\n2. Comorbidades\n3. Monitoramento\n4. Laboratoriais\n\nTodos as métricas laboratoriais e de monitoramento receberam as seguintes caracteristicas\n\n- Média\n- Mediana\n- Min\n- Max"},{"metadata":{"trusted":true},"cell_type":"code","source":"lab_feat = ['ALBUMIN',\n# 'DIFF_SET',           \n 'BE_ARTERIAL',\n 'BE_VENOUS',\n 'BIC_ARTERIAL',\n 'BIC_VENOUS',\n 'BILLIRUBIN',\n 'BLAST',\n 'CALCIUM',\n 'CREATININ',\n 'FFA',\n 'GGT',\n 'GLUCOSE',\n 'HEMATOCRITE',\n 'HEMOGLOBIN',\n 'INR',\n 'LACTATE',\n 'LEUKOCYTES',\n 'LINFOCITOS',\n 'NEUTROPHILES',\n 'P02_ARTERIAL',\n 'P02_VENOUS',\n 'PC02_ARTERIAL',\n 'PC02_VENOUS',\n 'PCR',\n 'PH_ARTERIAL',\n 'PH_VENOUS',\n 'PLATELETS',\n 'POTASSIUM',\n 'SAT02_ARTERIAL',\n 'SAT02_VENOUS',\n 'SODIUM',\n 'TGO',\n 'TGP',\n 'TTPA',\n 'UREA',\n 'DIMER']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monit_feat = [ 'BLOODPRESSURE_DIASTOLIC_MEAN',\n 'BLOODPRESSURE_SISTOLIC_MEAN',\n 'HEART_RATE_MEAN',\n 'RESPIRATORY_RATE_MEAN',\n 'TEMPERATURE_MEAN',\n 'OXYGEN_SATURATION_MEAN',\n 'BLOODPRESSURE_DIASTOLIC_MEDIAN',\n 'BLOODPRESSURE_SISTOLIC_MEDIAN',\n 'HEART_RATE_MEDIAN',\n 'RESPIRATORY_RATE_MEDIAN',\n 'TEMPERATURE_MEDIAN',\n 'OXYGEN_SATURATION_MEDIAN',\n 'BLOODPRESSURE_DIASTOLIC_MIN',\n 'BLOODPRESSURE_SISTOLIC_MIN',\n 'HEART_RATE_MIN',\n 'RESPIRATORY_RATE_MIN',\n 'TEMPERATURE_MIN',\n 'OXYGEN_SATURATION_MIN',\n 'BLOODPRESSURE_DIASTOLIC_MAX',\n 'BLOODPRESSURE_SISTOLIC_MAX',\n 'HEART_RATE_MAX',\n 'RESPIRATORY_RATE_MAX',\n 'TEMPERATURE_MAX',\n 'OXYGEN_SATURATION_MAX',\n 'BLOODPRESSURE_DIASTOLIC_DIFF',\n 'BLOODPRESSURE_SISTOLIC_DIFF',\n 'HEART_RATE_DIFF',\n 'RESPIRATORY_RATE_DIFF',\n 'TEMPERATURE_DIFF',\n 'OXYGEN_SATURATION_DIFF',\n 'BLOODPRESSURE_DIASTOLIC_DIFF_REL',\n 'BLOODPRESSURE_SISTOLIC_DIFF_REL',\n 'HEART_RATE_DIFF_REL',\n 'RESPIRATORY_RATE_DIFF_REL',\n 'TEMPERATURE_DIFF_REL',\n 'OXYGEN_SATURATION_DIFF_REL']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"demo_feat = ['AGE_ABOVE65',\n 'AGE_PERCENTIL']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"como_feat = ['DISEASE GROUPING 1',\n 'DISEASE GROUPING 2',\n 'DISEASE GROUPING 3',\n 'DISEASE GROUPING 4',\n 'DISEASE GROUPING 5',\n 'DISEASE GROUPING 6',\n 'HTN',\n 'IMMUNOCOMPROMISED',\n 'OTHER']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = ['ICU']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featurespace = [demo_feat,\ncomo_feat,\nmonit_feat,\nlab_feat,\ny]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(df.columns) - set([item for sublist in featurespace for item in sublist])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"PATIENT_VISIT_IDENTIFIER\", as_index = False).agg({\"ICU\":(list), \"WINDOW\":list})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Análises"},{"metadata":{"trusted":true},"cell_type":"code","source":"aux = abs(df.groupby(\"PATIENT_VISIT_IDENTIFIER\")[\"ICU\"].sum()-5)\naux = aux.value_counts().reset_index()\naux.sort_values(by = \"index\", inplace = True)\n\naux_map = {0:\"0-2\", 1:\"2-4\", 2:\"4-6\", 3:\"6-12\", 4:\"Above-12\",5:\"Never\"}\n\naux['index'] = aux['index'].map(aux_map)\naux.rename(columns = {'index':'WINDOW'},inplace=True)\naux.set_index('WINDOW',inplace= True)\n\ntotal_icu = aux.ICU.sum()\ny = aux.ICU[0:5].cumsum()/total_icu\n\ntot_icu_inpatients = aux.ICU[0:5].sum()\ny = aux.ICU[0:5].cumsum()/total_icu\nplt.plot(y, marker = \".\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NOVAS FEATURES"},{"metadata":{},"cell_type":"markdown","source":"## MISSING VALUES ARE STILL VALUES"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['MISSING DATA'] = df.isnull().sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['WINDOW']=='0-2']['MISSING DATA'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_miss = {}\nfor i in sorted(df[df['WINDOW']=='0-2']['MISSING DATA'].unique()):\n    tempdf = df[(df['MISSING DATA']==i) & (df['WINDOW']=='0-2')]\n    \n    dict_miss[i] = tempdf.columns[tempdf.isnull().all()].to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Break monit_feature into smaller groups\nbloodpressure_monit = [idx for idx in monit_feat if idx.startswith('BLOODPRESSURE')]\nheart_monit = [idx for idx in monit_feat if idx.startswith('HEART')]\noxygen_monit = [idx for idx in monit_feat if idx.startswith('OXYGEN')]\nrespiratory_monit = [idx for idx in monit_feat if idx.startswith('RESPIRATORY')]\ntemperature_monit = [idx for idx in monit_feat if idx.startswith('TEMPERATURE')]\n\nmonit_list = [bloodpressure_monit,heart_monit,oxygen_monit,respiratory_monit,temperature_monit]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_monit(missing_list):\n    '''given a list of columns with all NaN rows, this function returns what was not being monitored\n    false = no monitoring\n    true = monitoring'''\n    \n    monit_list = [bloodpressure_monit,heart_monit,oxygen_monit,respiratory_monit,temperature_monit]\n    \n    \n    print('______group with {} missing values_______'.format(i))\n    if set(bloodpressure_monit).issubset(set(missing_list)) == True:\n        print('Bloodpressure is NOT being monitored')\n    if set(heart_monit).issubset(set(missing_list)) == True:\n        print('Heart Rate is NOT being monitored')\n    if set(oxygen_monit).issubset(set(missing_list)) == True:\n        print('Oxygen level is NOT being monitored')\n    if set(respiratory_monit).issubset(set(missing_list)) == True:\n        print('Respirartory Frequency is NOT being monitored')\n    if set(temperature_monit).issubset(set(missing_list)) == True:\n        print('Body Temperature is NOT being monitored')\nfor i in dict_miss.keys():\n    check_monit(dict_miss[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Baseado nisso podemos criar features para cada um dos tipos de monitoramento"},{"metadata":{},"cell_type":"markdown","source":"# LABORATORY"},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_miss_lab = {}\nfor i in sorted(df[df['WINDOW']=='0-2']['MISSING DATA'].unique()):\n    tempdf = df[(df['MISSING DATA']==i) & (df['WINDOW']=='0-2')]\n    tempdf.drop(monit_feat,axis=1, inplace=True)\n    \n    dict_miss_lab[i] = tempdf.columns[tempdf.isnull().all()].to_list()\n    print(i)\n    print(tempdf.columns[tempdf.isnull().all()].to_list())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(dict_miss_lab[42]) == set(lab_feat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos usar exames laboratoriais como outra feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Criando novas features para cada conjunto de indicadores\n\ndf['missing_lab_exam'] = df[lab_feat].isnull().apply(lambda x: all(x), axis=1).astype(int)\ndf['missing_bloodpresure_monit'] = df[bloodpressure_monit].isnull().apply(lambda x: all(x), axis=1).astype(int)\ndf['missing_heart_monit'] = df[heart_monit].isnull().apply(lambda x: all(x), axis=1).astype(int)\ndf['missing_oxygen_monit'] = df[oxygen_monit].isnull().apply(lambda x: all(x), axis=1).astype(int)\ndf['missing_respiratory_monit'] = df[respiratory_monit].isnull().apply(lambda x: all(x), axis=1).astype(int)\ndf['missing_temperature_monit'] = df[temperature_monit].isnull().apply(lambda x: all(x), axis=1).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#Conferindo se existe ocorrencias de NaN que não são explicadas pelos 6 conjuntos acima\n\n(df['MISSING DATA']\\\n- (len(lab_feat)* df['missing_lab_exam'])\\\n- (len(bloodpressure_monit)* df['missing_bloodpresure_monit'])\\\n- (len(heart_monit)* df['missing_heart_monit'])\\\n- (len(oxygen_monit)* df['missing_oxygen_monit'])\\\n- (len(respiratory_monit)* df['missing_respiratory_monit'])\\\n- (len(temperature_monit)* df['missing_temperature_monit'])).unique()","execution_count":6,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'MISSING DATA'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'MISSING DATA'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-795a4eddb124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moxygen_monit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'missing_oxygen_monit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrespiratory_monit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'missing_respiratory_monit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m - (len(temperature_monit)* df['missing_temperature_monit'])).unique()\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'MISSING DATA'"]}]},{"metadata":{},"cell_type":"markdown","source":"# Preencher os NaN\n\n## Porque NaN =0"},{"metadata":{},"cell_type":"markdown","source":"# Mais algo?"},{"metadata":{},"cell_type":"markdown","source":"# OTHERS"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Deal with WINDOW and AGE_PERCENTIL variables\ndummies =  pd.get_dummies(df['AGE_PERCENTIL'])\n\ndf =pd.concat([df,dummies],axis=1)\ndf.drop('AGE_PERCENTIL',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_var =  df[['PATIENT_VISIT_IDENTIFIER','ICU']].groupby('PATIENT_VISIT_IDENTIFIER').sum('ICU')\n\ntarget_var['target']= target_var['ICU']>0\ntarget_var['target']= target_var['target'].astype('int')\ntarget_var.drop('ICU',axis=1,inplace=True)\n\ntarget_var","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y= target_var['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Trials"},{"metadata":{},"cell_type":"markdown","source":"## Ver. 1\n- replace NaNs with zero\n- use only 0-2 window"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(model1, y, test_size=0.3,stratify=y, random_state=11111993)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute   import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics  import accuracy_score, auc, roc_curve, precision_recall_curve, roc_auc_score, precision_score, recall_score, average_precision_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_evaluation(model, testing_set_x, testing_set_y):\n    predictions = model.predict_proba(testing_set_x)\n    \n    accuracy  = accuracy_score(testing_set_y, predictions[:,1] >= 0.5)\n    roc_auc   = roc_auc_score(testing_set_y, predictions[:,1])\n    precision = precision_score(testing_set_y, predictions[:,1] >= 0.5)\n    recall    = recall_score(testing_set_y, predictions[:,1] >= 0.5)\n    pr_auc    = average_precision_score(testing_set_y, predictions[:,1])\n    \n    result = pd.DataFrame([[accuracy, precision, recall, roc_auc, pr_auc]], columns=['Accuracy', 'Precision', 'Recall', 'ROC_auc','PR_auc'])\n    return(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_hyperparameters = {\n              'n_estimators':2100,\n              'max_depth':27,\n              'min_samples_split':2,\n              'min_samples_leaf':4,\n              'random_state':451,\n            }\n\n\nclf = RandomForestClassifier(**rf_optimal)\n\nclf.fit(X_train,y_train)\n\nmodel_evaluation(clf, X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = df.copy()\nmodel1 = model1[model1['WINDOW'] == '0-2']\nmodel1 = model1.fillna(0)\nmodel1 = model1.reset_index()\n\nmodel1.drop(['index','PATIENT_VISIT_IDENTIFIER','MISSING DATA','WINDOW'],axis=1,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = df.copy()\nmodel2 = model2.fillna(0)\n\ntarget_mapping = target_var['target'].to_dict()\nmodel2['target'] = model2['PATIENT_VISIT_IDENTIFIER'].map(target_mapping)\n\nmodel2.reset_index(drop=True)\nmodel2.drop(['PATIENT_VISIT_IDENTIFIER','MISSING DATA','WINDOW'],axis=1,inplace=True)\n\ny = model2.pop('target')\nX = model2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y, random_state=11111993)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_hyperparameters = {\n              'n_estimators':2100,\n              'max_depth':27,\n              'min_samples_split':2,\n              'min_samples_leaf':4,\n              'random_state':451,\n            }\n\n\nclf = RandomForestClassifier(**rf_optimal)\n\nclf.fit(X_train,y_train)\n\nmodel_evaluation(clf, X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}